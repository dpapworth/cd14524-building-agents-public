{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Import the necessary libs\n",
    "# For example: \n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage\n",
    "from lib.tooling import tool\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# \n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) -> List:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "    args:\n",
    "    - query: a question about game industry. \n",
    "\n",
    "    You'll receive results as list. Each element contains:\n",
    "    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "    - Name: Name of the Game\n",
    "    - YearOfRelease: Year when that game was released for that platform\n",
    "    - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling retrieve_game: query=\\\"{query}\\\"\")\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=10\n",
    "    )\n",
    "\n",
    "    metadatas = results.get(\"metadatas\", [[]])[0]\n",
    "\n",
    "    result = [\n",
    "        {\n",
    "            \"Platform\": m.get(\"Platform\"),\n",
    "            \"Name\": m.get(\"Name\"),\n",
    "            \"YearOfRelease\": m.get(\"YearOfRelease\"),\n",
    "            \"Description\": m.get(\"Description\")\n",
    "        }\n",
    "        for m in metadatas\n",
    "    ]\n",
    "\n",
    "    print(f\"Returning: {json.dumps(result, indent=2)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "\n",
    "judge_llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "class EvaluationResult(BaseModel):\n",
    "    useful: bool = Field(..., description=\"Whether the documents are useful to answer the question.\")\n",
    "    description: str = Field(..., description=\"Explanation of why the documents are or are not useful.\")\n",
    "\n",
    "class EvaluationResultList(BaseModel):\n",
    "    evaluations: List[EvaluationResult]\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: List) -> Dict:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "\n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "\n",
    "    The result includes:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling evaluate_retrieval: question=\\\"{question}\\\", retrieved_docs={json.dumps(retrieved_docs, indent=2)}\")\n",
    "\n",
    "    response = judge_llm.invoke([\n",
    "        SystemMessage(content=\"\"\"\n",
    "Your task is to evaluate if the documents are enough to respond the query.\n",
    "Give a detailed explanation, so it's possible to take an action to accept it or not.\n",
    "        \"\"\"),\n",
    "        UserMessage(content=f\"\"\"\n",
    "The user asked:\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Retrieved Documents\n",
    "{json.dumps(retrieved_docs, indent=2)}\n",
    "\n",
    "Evaluate **each** document *individually*.\n",
    "\n",
    "For each document:\n",
    "1. Determine whether this single document is useful for answering the question.\n",
    "2. Provide a short explanation.\n",
    "\n",
    "Return the output in the following JSON structure:\n",
    "\n",
    "{{\n",
    "  \"evaluations\": [\n",
    "    {{\n",
    "      \"useful\": true/false,\n",
    "      \"description\": \"short explanation for doc #1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"useful\": true/false,\n",
    "      \"description\": \"short explanation for doc #2\"\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "        \"\"\")\n",
    "    ],\n",
    "        response_format=EvaluationResultList\n",
    "    )\n",
    "\n",
    "    result = json.loads(response.content)\n",
    "\n",
    "    print(f\"Returning {json.dumps(result, indent=2)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. \n",
    "@tool\n",
    "def game_web_search(query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Search the web using Tavily API\n",
    "    args:\n",
    "    - question: a question about game industry. \n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling game_web_search: query=\\\"{query}\\\"\")\n",
    "\n",
    "    client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "    # Perform the search\n",
    "    search_result = client.search(\n",
    "        query=query,\n",
    "        search_depth=\"advanced\",\n",
    "        include_answer=True,\n",
    "        include_raw_content=False,\n",
    "        include_images=False\n",
    "    )\n",
    "\n",
    "    # Format the results\n",
    "    result = {\n",
    "        \"answer\": search_result.get(\"answer\", \"\"),\n",
    "        \"results\": search_result.get(\"results\", []),\n",
    "        \"search_metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"Returning {json.dumps(result, indent=2)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "\n",
    "agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=\"\"\"\n",
    "You are UdaPlay, an AI Research Agent for the video game industry.\n",
    "\n",
    "When answering questions about video games:\n",
    "1. Find documents in the vector DB\n",
    "2. Evaluate the quality of retrieved results\n",
    "3. If no results are useful, use search the web for game information\n",
    "4. Provide comprehensive answers, and include proper citations for web sources\n",
    "\n",
    "You have access to these tools and should decide when to use each one based on the query and results.\n",
    "Only use knowledge retrieved using tool calls.\n",
    "    \"\"\",\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb3e91-b562-4476-8d1d-558eba79857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_agent(question: str):\n",
    "    run_object = agent.invoke(question)\n",
    "\n",
    "    # Return last message generated by the agent\n",
    "    last_message = run_object.get_final_state()[\"messages\"][-1]\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer  : {last_message.content}\")\n",
    "\n",
    "invoke_agent(\"When Pokémon Gold and Silver was released?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb236fe-41a3-4370-88f8-da376d4d14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_agent(\"Which one was the first 3D platformer Mario game?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f23b4-bd64-416b-8dea-862a78e511f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_agent(\"Was Mortal Kombat X realeased for Playstation 5?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
