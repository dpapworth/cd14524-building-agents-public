{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Import the necessary libs\n",
    "# For example: \n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, TypedDict, Union\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage, BaseMessage\n",
    "from lib.tooling import tool\n",
    "from lib.rag import RAG\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Resource\n",
    "from lib.vector_db import VectorStore\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# \n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")\n",
    "\n",
    "@tool\n",
    "def retrieve_game(query: str) :\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "    args:\n",
    "    - query: a question about game industry. \n",
    "\n",
    "    You'll receive results as list. Each element contains:\n",
    "    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "    - Name: Name of the Game\n",
    "    - YearOfRelease: Year when that game was released for that platform\n",
    "    - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling retrieve_game: query=\\\"{query}\\\"\")\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=10\n",
    "    )\n",
    "\n",
    "    metadatas = results.get(\"metadatas\", [[]])[0]\n",
    "\n",
    "    result = [\n",
    "        {\n",
    "            \"Platform\": m.get(\"Platform\"),\n",
    "            \"Name\": m.get(\"Name\"),\n",
    "            \"YearOfRelease\": m.get(\"YearOfRelease\"),\n",
    "            \"Description\": m.get(\"Description\")\n",
    "        }\n",
    "        for m in metadatas\n",
    "    ]\n",
    "\n",
    "    print(f\"Returning: {json.dumps(result, indent=2)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result\n",
    "\n",
    "judge_llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "class EvaluationResult(BaseModel):\n",
    "    useful: bool = Field(..., description=\"Whether the documents are useful to answer the question.\")\n",
    "    description: str = Field(..., description=\"Explanation of why the documents are or are not useful.\")\n",
    "\n",
    "class EvaluationResultList(BaseModel):\n",
    "    evaluations: List[EvaluationResult]\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: list) -> Dict:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "\n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "\n",
    "    The result includes:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling evaluate_retrieval: question=\\\"{question}\\\", retrieved_docs={json.dumps(retrieved_docs, indent=2)}\")\n",
    "\n",
    "    response = judge_llm.invoke([\n",
    "        SystemMessage(content=\"\"\"\n",
    "Your task is to evaluate if the documents are enough to respond the query.\n",
    "Give a detailed explanation, so it's possible to take an action to accept it or not.\n",
    "        \"\"\"),\n",
    "        UserMessage(content=f\"\"\"\n",
    "The user asked:\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Retrieved Documents\n",
    "{json.dumps(retrieved_docs, indent=2)}\n",
    "\n",
    "Evaluate **each** document *individually*.\n",
    "\n",
    "For each document:\n",
    "1. Determine whether this single document is useful for answering the question.\n",
    "2. Provide a short explanation.\n",
    "\n",
    "Return the output in the following JSON structure:\n",
    "\n",
    "{{\n",
    "  \"evaluations\": [\n",
    "    {{\n",
    "      \"useful\": true/false,\n",
    "      \"description\": \"short explanation for doc #1\"\n",
    "    }},\n",
    "    {{\n",
    "      \"useful\": true/false,\n",
    "      \"description\": \"short explanation for doc #2\"\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "        \"\"\")\n",
    "    ],\n",
    "        response_format=EvaluationResultList\n",
    "    )\n",
    "\n",
    "    result = json.loads(response.content)\n",
    "\n",
    "    print(f\"Returning {json.dumps(result, indent=2)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. \n",
    "@tool\n",
    "def game_web_search(query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Search the web using Tavily API\n",
    "    args:\n",
    "    - question: a question about game industry. \n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling game_web_search: query=\\\"{query}\\\"\")\n",
    "\n",
    "    client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "    # Perform the search\n",
    "    search_result = client.search(\n",
    "        query=query,\n",
    "        search_depth=\"advanced\",\n",
    "        include_answer=True,\n",
    "        include_raw_content=False,\n",
    "        include_images=False\n",
    "    )\n",
    "\n",
    "    # Format the results\n",
    "    result = {\n",
    "        \"answer\": search_result.get(\"answer\", \"\"),\n",
    "        \"results\": search_result.get(\"results\", []),\n",
    "        \"search_metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(f\"Returning {json.dumps(result, indent=2)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed\n",
    "\n",
    "# Define agent state\n",
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    doc_search_results: List\n",
    "    doc_evaluation_results: List\n",
    "    doc_filtered_results: List\n",
    "    web_search_results: Dict\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26966a55-cea6-4061-864c-e4762fe43fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_search(state: State) -> State:\n",
    "    # Look up results\n",
    "    results = retrieve_game(state[\"question\"])\n",
    "    state[\"doc_search_results\"] = results\n",
    "    return state\n",
    "\n",
    "def doc_evaluate(state: State) -> State:\n",
    "    # Evaluate results and discard irrelevant results\n",
    "    evaluation_results = evaluate_retrieval(state[\"question\"], state[\"doc_search_results\"])\n",
    "    state[\"doc_evaluation_results\"] = evaluation_results[\"evaluations\"]\n",
    "    return state\n",
    "\n",
    "def doc_filter(state: State) -> State:\n",
    "    doc_search_results = state[\"doc_search_results\"]\n",
    "    doc_evaluation_results = state[\"doc_evaluation_results\"]\n",
    "    state[\"doc_filtered_results\"] = [\n",
    "        doc_search_result\n",
    "        for doc_search_result, evaluation_result in zip(doc_search_results, doc_evaluation_results)\n",
    "        if evaluation_result[\"useful\"]\n",
    "    ]\n",
    "    return state\n",
    "\n",
    "def doc_answer(state: State) -> State:\n",
    "    output_llm = LLM(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    response = output_llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"\n",
    "Your task is to output the answer to a question, given retrieved documents containing the relevant information.\n",
    "        \"\"\"),\n",
    "        UserMessage(content=f\"\"\"\n",
    "The user asked:\n",
    "\n",
    "### Question\n",
    "{state[\"question\"]}\n",
    "\n",
    "### Retrieved Documents\n",
    "{json.dumps(state[\"doc_filtered_results\"], indent=2)}\n",
    "        \"\"\")\n",
    "    ])\n",
    "    state[\"result\"] = response.content\n",
    "    return state\n",
    "\n",
    "def web_search(state: State) -> State:\n",
    "    state[\"web_search_results\"] = game_web_search(state[\"question\"])\n",
    "    return state\n",
    "\n",
    "def web_answer(state: State) -> State:\n",
    "    output_llm = LLM(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    response = output_llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"\n",
    "Your task is to output the answer to a question, given web search results. Include citations to URLs in your answer.\n",
    "        \"\"\"),\n",
    "        UserMessage(content=f\"\"\"\n",
    "The user asked:\n",
    "\n",
    "### Question\n",
    "{state[\"question\"]}\n",
    "\n",
    "### Web Search Results\n",
    "{json.dumps(state[\"web_search_results\"], indent=2)}\n",
    "        \"\"\")\n",
    "    ])\n",
    "    state[\"result\"] = response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7ed1d-2556-42c6-a613-240498215434",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateMachine(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb1884-97d0-499c-8183-b12938e7a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "entry = EntryPoint()\n",
    "doc_search_step = Step[State](\"doc_search\", doc_search)\n",
    "doc_evaluate_step = Step[State](\"doc_evaluate\", doc_evaluate)\n",
    "doc_filter_step = Step[State](\"doc_filter\", doc_filter)\n",
    "doc_answer_step = Step[State](\"doc_answer\", doc_answer)\n",
    "web_search_step = Step[State](\"web_search\", web_search)\n",
    "web_answer_step = Step[State](\"web_answer\", web_answer)\n",
    "termination = Termination()\n",
    "\n",
    "workflow.add_steps(\n",
    "    [\n",
    "        entry, \n",
    "        doc_search_step, \n",
    "        doc_evaluate_step, \n",
    "        doc_answer_step, \n",
    "        doc_filter_step,\n",
    "        web_search_step,\n",
    "        web_answer_step,\n",
    "        termination\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafccd35-7ab9-403c-88c3-02de6db91d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transitions\n",
    "workflow.connect(entry, doc_search_step)\n",
    "workflow.connect(doc_search_step, doc_evaluate_step)\n",
    "workflow.connect(doc_evaluate_step, doc_filter_step)\n",
    "\n",
    "def check_doc_results(state) -> Union[Step[State], str]:\n",
    "    if state[\"doc_filtered_results\"]:\n",
    "        return doc_answer_step\n",
    "    return web_search_step\n",
    "\n",
    "workflow.connect(doc_filter_step, [doc_answer_step, web_search_step], check_doc_results)\n",
    "workflow.connect(doc_answer_step, termination)\n",
    "workflow.connect(web_search_step, web_answer_step)\n",
    "workflow.connect(web_answer_step, termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb3e91-b562-4476-8d1d-558eba79857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_agent(question: str) -> str:\n",
    "    initial_state: State = {\n",
    "        \"question\": question\n",
    "    }\n",
    "    run_object = workflow.run(initial_state)\n",
    "    return run_object.get_final_state()[\"result\"]\n",
    "\n",
    "print(invoke_agent(\"When Pokémon Gold and Silver was released?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb236fe-41a3-4370-88f8-da376d4d14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(invoke_agent(\"Which one was the first 3D platformer Mario game?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f23b4-bd64-416b-8dea-862a78e511f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(invoke_agent(\"Was Mortal Kombat X realeased for Playstation 5?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
